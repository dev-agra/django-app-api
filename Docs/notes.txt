github actions is similar to CI/CD and Jenkins

uses:
deployment
linting
unit testing

working:
triggers-> push to github
setup jobs-> run when triggers are hit
output i.e. a job is success or not

charged per minutes

configure github actions
-> create a config file
-> configure docker hub auth

Docker hub:
base images
pull images from docker
rate limits
100 images / 6hrs
auth users 200 pull images/6hrs

github actions uses shared ip thus configure with docker hub
so 200 pulls are to us and us only

so how to authenticate?
-> register with dockerhub
-> use docker login
-> add secrets to projects[variables to projects]


Django test
-> based on unittest lib
-> DRF additional features

How?
place test.py in each app
or
test/ subdirectory (only one way) -> must have __init__.py in each app

test database
test code that uses DB
creates a diff test database
happens for every test

test classes:
SimpleTestCase -> no DB
TestCase -> normal with DB


prefix everything related to test with test_

Mocking
->override or change behaviour of dependencies
->isolation of code being tested

why mocking?
-> avoid external relying
-> avoid unintended consequences like overloading

example:
register user -> create user -> send email
so to test it we wouldn't want to send user email so we change the codebase accordingly

how to mock?
use unittest.mock
MagicMock/Mock -> replace real obj
patch -> overrides code obj

use APIClient
make requests
check result
override auth

Testing issues
-> not running(missing __init__, indentation, both /tests dir and test module so confusing)


Django with database
needs to know
-> engine-type
-> hostname
-> port
-> db name
-> username
-> password


Environment Variable:
-> pull config values from env variables
-> local or prod
-> single pkace of configuration
-> easy with python-> os.environ.get('DB_HOST)
-> Psycopg2 is used for django to connect to postgres

Psycopg2
-> psycopg2-binary - ok for dev but not prod - dependencies -> C compiler, python3, libq-dev
-> psycopg2 - compiles froms source - easy for docker

for alpine image
postgresql-client
build-base
postgres-dev
musl-dev


DB RACE CONDITION
depends_on makes sure that service starts but doesn't make sure about the application is running
i.e. services starts but no garantee the application is running in it

Solution is -> WAIT FOR DB

Django ORM
object relational mapper
-> abstraction layer for data; django handles db structure and changes
-> focus on python code
-> use any db

use ORM
-> define models
-> generate migration files
-> setup db (run migrations file)
-> store data

Model
each model maps to a table
models contain(name, fields(columns), Other metadata(Relations), Python Logic)

Create migrations
-> ensure app is in settings.py
-> checks model and see if it exists before

-> best to run migrations after "wait _for_db" i.e. race condition so that the db is ready and any changes is updated in the db

Update Docker Compose so cmd of "wait_for_db" runs before the server starting and CI/CD config too

Django Authentication:
Django authentication is built-in
integrates with django admin
default user model->(username rather mail, not customise)

-> create new cutom user model
-> allows email rather username
-> future proof

How to cutomise User Model:
-> create user model from AbstractBaseUser and PermissionsMixin
-> custom manager
-> set AUTH_USER_MODEL
-> create and run migrations

AbstractBaseUser
-> provides features for authentication
->                                                                                                                                                                                

PermissionsMixin
-> support for django permission system
-> includes fields and methods

Django Admin
-> interface to control things
-> less code required
-> enable per model

"admin.set.reigtser(modelname)"

Customize Django Admin
-> create class based on ModelAdmin and UserAdmin
-> override it

1) Change list of objects
-> orderig(order of item appear)
-> list_display(field to appear in list)

2) Add/Update page
-> fieldsets
-> readonly_fields

API DOCUMENTATION
-> developers to use

WHAT TO DOCUMENT
-> everything needed to use API
-> available endpoints(paths)...say.../api/recipes
-> supported methods (GET, POST, PUT, PATCH, DELETE)
-> format of payloads [input] (parameters, JSON)
-> format of response (JSON)
-> authentication process

OPTION OF DOCUMENT
-> word doc
-> markdown
-> Automated(metadata)(comments)(generate documentation)

AUTO DOCS IN DRF
-> 3rd party library (drf-spectacular)
-> follows latest openai api standard
-> generates schema
-> schema helps to create browsable web interface (test req, auth)

HOW IT WORKS
-> generate schema
-> parse schema file

OPENAPI Schema
-> standard for desc API
-> popular
-> swagger (we uses it)
-> YAML or JSON
